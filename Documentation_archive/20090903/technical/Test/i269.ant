========================================================================

File:      $RCSfile: i269.ant,v $
Version:   $Revision: 1.1 $
Modified:  $Date: 2009/09/03 18:28:17 $

(c) Copyright 2004-2009 by Mentor Graphics Corp. All rights reserved.

========================================================================
This document contains information proprietary and confidential to
Mentor Graphics Corp., and is not for external distribution.
========================================================================

Tiger Project Analysis Note
System Test Strategy

Abstract
--------
We need to perform a full system wide black box test on Tiger prior to each
customer release. This note describes the strategy to be followed to create the
test plan needed for this task.

History
-------

Document References
-------------------
[1] Bugzilla issue 269
[2] www.mercury.com/us/products/quality-center/functional-testing/winrunner/
[3] www.cenqua.com/clover/
[4] internal/technical/Test/Coverage_tools.txt

Background
----------
This note specifies the criteria to be used to determine whether the Tiger
BridgePoint Builder replacement meets the quality standards necessary for
customer release.

Analysis
--------
This note does not attempt to enumerate the tests or test areas to be covered by
System Test. This would merely lead to an unnecessary maintainance overhead as
the product continues to develop. Instead, it sets out test strategy, coverage
and reliability criteria to be met prior to each release.

Strategy
--------
The current Unit test strategy employed is more comprehensive than one might
expect from the term 'Unit Test'. The tests are automated and take a fairly
system wide approach to testing the product rather than the rather narrow scope
implied by the unit test term. Repeating this automated test would not be a good
strategy for a system test, since the tests have all been done before each
engineering task is considered complete. However, the current unit tests do
make use of knowledge about how each feature is implemented and often inject
events or method calls directly into the unit under test in order to set pre-
conditions or to test post-conditions.

In contrast, the system tests shall take a much more Black Box approach and
shall not be allowed to access any part of the tool other than through the user
interface. To achieve this, we shall employ a test automation tool such as
WinRunner[2] to push buttons, and check outcomes.

Coverage
--------
Nothing less than 100% code coverage shall be acceptable as a code coverage
criterion. Even this does not fully exercise the tool, since there are many
combinatorial path alternatives that must be visited in order to fully test the
tool. Initially at least, we will exempt exception handling code from this path
coverage criterion, since much of it should never be executed. Achieving 100%
code coverage is an achievable but challenging goal. In order to demonstrate
compliance with this criterion, we shall execute the system test with an Eclipse
compatible code coverage tool such as Clover[3]. We have already evaluated the
available code coverage tools[4]. However, this data may well be out of date and
we should revisit these products to see what progress has been made.

Reliability Criterion
---------------------
Tiger shall meet or exceed a Mean Time Between Failures (MTBF) criterion of 2000
hours with 3 months of initial release. This goal shall be demonstrated prior to
release by calculating the release co-efficient of the decay curve of defects
found over time using the expression:

          R = e ^ - (lambda t)
  
Where R is reliability measured as MTBF, t is the time at which the observation
is made, e is the exponent constant and lambda the release co-efficient, used to
predict reliability at some point in the future. The required input data
(R and t) shall be available from defect data gathered during the final system
test phase of the project.

Work Required
-------------
269.1   Select UI level automated test runner
269.2   Select Code coverage tool
269.3   Create test plan that enumerates the tests to be executed
269.4   Enhance the automated test so that the start and end times of the test
        runs are captured. This is used to calculate t in the equation above.
269.5   Extend the process to ensure that information about defects detected
        during system test can be extracted from Bugzilla. This is used to
        calculate R.
269.6   Develop an automated method that can accept the data obtained above and
        give an estimate for lambda (the coefficient can be calculated using a
        least mean squares method).

End
---

$Log: i269.ant,v $
Revision 1.1  2009/09/03 18:28:17  rmulvey
job:dts0100616734
Archive documentation and other development notes following the R3_0_0 release.  These are being archived under Documentation/internal/technical/archive/20090903

Revision 1.4  2009/01/01 23:13:39  rmulvey
Job:4060
Batch promotion of copyright changes from Review-i4060 and Review-i4060-01.

Revision 1.3.50.1  2008/12/31 16:10:53  rmulvey
Job:4060
This is a batch commit of 2009 copyright changes to branch Review-i4060.  This includes the
report that outlines all changes made (before/after for each line changed).  This report is found here: <cvs>/Documentation/internal/test_results/R2_1_2/i4060/update-copyright-results.txt.

Revision 1.3  2005/02/02 16:53:03  campbell
Job: 269
Review observations addressed.

Revision 1.2  2005/01/20 22:14:03  campbell
Job: 269
Added web references and included reference
to existing code coverage work..

Revision 1.1  2005/01/20 22:03:20  campbell
Job: 269
Introduced.

